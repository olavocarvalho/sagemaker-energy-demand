{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Energy Demand\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "The project consists of two data sets:\n",
    "* Hourly electricity demand data from the EIA;\n",
    "* Hourly observed weather data from LCD/NOAA. \n",
    "\n",
    "Additionally to demand and weather data, I'll create features based on time to see how the trends are impacted by day of week, hour, week of year, if is holiday, etc.\n",
    "\n",
    "To limit the scope of the project, I'll use data from Los Angeles exclusively to validate if is possible to improve electricity demand forecasting using weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket ='sagemaker-data-energy-demand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_CLIENT = boto3.client('s3')\n",
    "files_list = S3_CLIENT.list_objects_v2(Bucket=bucket, Prefix='raw_data/weather/')\n",
    "s3_files = files_list['Contents']        \n",
    "latest_weather_data = max(s3_files, key=lambda x: x['LastModified'])\n",
    "\n",
    "weather_data_location = 's3://{}/{}'.format(bucket, latest_weather_data['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electricity data \n",
    "Electricity data were retrieved using EIA’s API and then unpacked into a dataframe. The API contain hourly entries from July 2015 to present.\n",
    "\n",
    "The electricity data required just simple cleaning. There were few null values in the set and a very small number of outliers. Removing outliers cut only ~.01% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIA__API_KEY = '1d48c7c8354cc4408732174250d3e8ff'\n",
    "REGION_CODE = 'LDWP'\n",
    "CITY = 'LosAngeles'\n",
    "\n",
    "def str_to_isodatetime(string):\n",
    "    '''\n",
    "    This function transforms strings to an ISO Datetime.\n",
    "    '''\n",
    "    year = string[:4]\n",
    "    month = string[4:6]\n",
    "    day =  string[6:8]\n",
    "    time = string[8:11] + ':00:00+0000'\n",
    "    return year + month + day + time\n",
    "\n",
    "def eia2dataframe(response):\n",
    "    '''\n",
    "    This function unpacks the JSON file from EIA API into a pandas dataframe.\n",
    "    '''\n",
    "    data = response['series'][0]['data']\n",
    "    dates = []\n",
    "    values = []\n",
    "    for date, demand in data:\n",
    "        if demand is None or demand <= 0:\n",
    "            dates.append(str_to_isodatetime(date))\n",
    "            values.append(np.nan)      \n",
    "            continue   \n",
    "        dates.append(str_to_isodatetime(date))\n",
    "        values.append(float(demand))\n",
    "    df = pd.DataFrame({'datetime': dates, 'demand': values})\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df['demand'] = df['demand'].interpolate()\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.sort_index(ascending=True, inplace=True, kind='mergesort')\n",
    "    return df\n",
    "\n",
    "electricity_api_response = requests.get('http://api.eia.gov/series/?api_key=%s&series_id=EBA.%s-ALL.D.H' % (EIA__API_KEY, REGION_CODE)).json()\n",
    "electricity_df = eia2dataframe(electricity_api_response)\n",
    "electricity_df = electricity_df[electricity_df['demand'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed weather data\n",
    "LCD data are not available via NOAA’s API so I manually downloaded from the website as a CSV file which I imported to a pandas DataFrame. As common in data that come from physical sensors, LCD data required extensive cleansing.\n",
    "\n",
    "The main challenges in cleaning the LCD data was that there were in some cases multiple entries for the same hour. I wanted to have just one entry per hour such that I could eventually align LCD data with the hourly entries in the electricity data.\n",
    "\n",
    "I wrote a function that group weather data by hour and the mode of the entries for same hour. I performed the cleaning this way because either way, the values for multiple per-hour entries are very similar, so the choice of which entry to keep doesn’t make a real difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date(df):\n",
    "    '''\n",
    "    This function goes through the dates in the weather dataframe and if there is more than one record for each\n",
    "    hour, we pick the record closest to the hour and drop the rows with the remaining records for that hour.\n",
    "    This is so we can align this dataframe with the one containing electricity data.'''\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date']).dt.tz_localize('UTC')\n",
    "    df['date_rounded'] = df['date'].dt.floor('H')\n",
    "    df.drop('date', axis=1, inplace=True)\n",
    "    df.rename({\"date_rounded\": \"datetime\"}, axis=1, inplace=True)\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    last_of_hour = df[~df.index.duplicated(keep='last')]    \n",
    "    last_of_hour.sort_index(ascending=True, inplace=True, kind='mergesort')\n",
    "    \n",
    "    return last_of_hour\n",
    "    \n",
    "def clean_sky_condition(df):\n",
    "    '''\n",
    "    This function cleans the hourly sky condition column by assigning the hourly sky condition to be the one at the\n",
    "    top cloud layer, which is the best determination of the sky condition, as described by the documentation.\n",
    "    '''\n",
    "    conditions = df['hourlyskyconditions']\n",
    "    new_condition = []\n",
    "    for k, condition in enumerate(conditions):\n",
    "        if type(condition) != str and np.isnan(condition):\n",
    "            new_condition.append(np.nan)\n",
    "        else:\n",
    "            colon_indices = [i for i, char in enumerate(condition) if char == ':']\n",
    "            n_layers = len(colon_indices)\n",
    "            try:\n",
    "                colon_position = colon_indices[n_layers - 1]\n",
    "                if condition[colon_position - 1] == 'V':\n",
    "                    condition_code = condition[colon_position - 2 : colon_position]\n",
    "                else:\n",
    "                    condition_code = condition[colon_position - 3 : colon_position]\n",
    "                new_condition.append(condition_code)\n",
    "            except:\n",
    "                new_condition.append(np.nan)\n",
    "\n",
    "    df['hourlyskyconditions'] = new_condition\n",
    "    df['hourlyskyconditions'] = df['hourlyskyconditions'].astype('category')\n",
    "    return df\n",
    "\n",
    "def hourly_degree_days(df):\n",
    "    '''\n",
    "    This function adds hourly heating and cooling degree days to the weather DataFrame.\n",
    "    '''\n",
    "    df['hourlycoolingdegrees'] = df['hourlydrybulbtemperature'].apply(lambda x: x - 65. if x >= 65. else 0.)\n",
    "    df['hourlyheatingdegrees'] = df['hourlydrybulbtemperature'].apply(lambda x: 65. - x if x <= 65. else 0.)\n",
    "    return df\n",
    "\n",
    "# import csv\n",
    "weather_df = pd.read_csv(weather_data_location, usecols=['DATE', 'DailyCoolingDegreeDays', 'DailyHeatingDegreeDays', 'HourlyDewPointTemperature', 'HourlyPrecipitation', 'HourlyRelativeHumidity', 'HourlySeaLevelPressure', 'HourlySkyConditions', 'HourlyStationPressure', 'HourlyVisibility', 'HourlyDryBulbTemperature', 'HourlyWindSpeed'],\n",
    "                        dtype={\n",
    "                                'DATE': object,\n",
    "                                'DailyCoolingDegreeDays': object,\n",
    "                                'DailyHeatingDegreeDays': object,\n",
    "                                'HourlyDewPointTemperature': object,\n",
    "                                'HourlyPrecipitation': object,\n",
    "                                'HourlyRelativeHumidity': object,\n",
    "                                'HourlySeaLevelPressure': object,\n",
    "                                'HourlySkyConditions': object,\n",
    "                                'HourlyStationPressure': object,\n",
    "                                'HourlyVisibility': object,\n",
    "                                'HourlyDryBulbTemperature': object,\n",
    "                                'HourlyWindSpeed': object\n",
    "                        })\n",
    "\n",
    "# make columns lowercase for easier access\n",
    "weather_df.columns = [col.lower() for col in weather_df.columns]\n",
    "\n",
    "# clean dataframe so that there's only one record per hour\n",
    "weather_df = fix_date(weather_df)\n",
    "\n",
    "# fill the daily heating and cooling degree days such that each hour in an individual day has the same value\n",
    "weather_df['dailyheatingdegreedays'] = weather_df['dailyheatingdegreedays'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "weather_df.dailyheatingdegreedays.astype('float64')\n",
    "weather_df['dailycoolingdegreedays'] = weather_df['dailycoolingdegreedays'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "weather_df.dailycoolingdegreedays.astype('float64')\n",
    "weather_df['dailyheatingdegreedays'] = weather_df['dailyheatingdegreedays'].bfill()\n",
    "weather_df['dailycoolingdegreedays'] = weather_df['dailycoolingdegreedays'].bfill()\n",
    "\n",
    "weather_df = clean_sky_condition(weather_df)\n",
    "\n",
    "# clean other columns by replacing string based values with floats\n",
    "# values with an 's' following indicate uncertain measurments. we simply change those to floats and include them like normal\n",
    "weather_df['hourlyvisibility'] = weather_df['hourlyvisibility'].apply(lambda x: float(x) if str(x)[-1] != 'V' else float(str(x)[:-1]))\n",
    "\n",
    "weather_df['hourlydrybulbtemperature'] = weather_df['hourlydrybulbtemperature'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "\n",
    "weather_df['hourlydewpointtemperature'] = weather_df['hourlydewpointtemperature'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "\n",
    "# set trace amounts equal to zero and change data type\n",
    "weather_df['hourlyprecipitation'].where(weather_df['hourlyprecipitation'] != 'T', 0.0, inplace=True)\n",
    "weather_df['hourlyprecipitation'] = weather_df['hourlyprecipitation'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "weather_df['hourlystationpressure'] = weather_df['hourlystationpressure'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "weather_df['hourlywindspeed'] = weather_df['hourlywindspeed'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "weather_df['hourlyrelativehumidity'] = weather_df['hourlyrelativehumidity'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "weather_df['hourlysealevelpressure'] = weather_df['hourlysealevelpressure'].apply(lambda x: float(x) if str(x)[-1] != 's' else float(str(x)[:-1]))\n",
    "\n",
    "weather_df.hourlyprecipitation.astype('float64')\n",
    "weather_df.hourlyvisibility.astype('float64')\n",
    "weather_df.hourlyrelativehumidity.astype('float64')\n",
    "weather_df.hourlysealevelpressure.astype('float64')\n",
    "weather_df.hourlystationpressure.astype('float64')\n",
    "weather_df.hourlywindspeed.astype('float64')\n",
    "\n",
    "weather_df = hourly_degree_days(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44022, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2015-01-01 00:00:00+00:00    30.06\n",
       "2015-01-01 01:00:00+00:00    30.07\n",
       "2015-01-01 02:00:00+00:00    30.08\n",
       "2015-01-01 03:00:00+00:00    30.08\n",
       "2015-01-01 04:00:00+00:00    30.09\n",
       "2015-01-01 05:00:00+00:00    30.11\n",
       "2015-01-01 06:00:00+00:00    30.13\n",
       "2015-01-01 07:00:00+00:00    30.14\n",
       "2015-01-01 08:00:00+00:00    30.15\n",
       "2015-01-01 09:00:00+00:00    30.17\n",
       "2015-01-01 10:00:00+00:00    30.16\n",
       "2015-01-01 11:00:00+00:00    30.13\n",
       "2015-01-01 12:00:00+00:00    30.11\n",
       "2015-01-01 13:00:00+00:00    30.10\n",
       "2015-01-01 14:00:00+00:00    30.09\n",
       "2015-01-01 15:00:00+00:00    30.10\n",
       "2015-01-01 16:00:00+00:00    30.11\n",
       "2015-01-01 17:00:00+00:00    30.12\n",
       "2015-01-01 18:00:00+00:00    30.14\n",
       "2015-01-01 19:00:00+00:00    30.14\n",
       "2015-01-01 20:00:00+00:00    30.14\n",
       "2015-01-01 21:00:00+00:00    30.14\n",
       "2015-01-01 22:00:00+00:00    30.14\n",
       "2015-01-01 23:00:00+00:00      NaN\n",
       "2015-01-02 00:00:00+00:00    30.13\n",
       "2015-01-02 01:00:00+00:00    30.14\n",
       "2015-01-02 02:00:00+00:00    30.13\n",
       "2015-01-02 03:00:00+00:00    30.12\n",
       "2015-01-02 04:00:00+00:00    30.12\n",
       "2015-01-02 05:00:00+00:00    30.13\n",
       "                             ...  \n",
       "2020-01-13 18:00:00+00:00    30.09\n",
       "2020-01-13 19:00:00+00:00    30.08\n",
       "2020-01-13 20:00:00+00:00    30.09\n",
       "2020-01-13 21:00:00+00:00    30.10\n",
       "2020-01-13 22:00:00+00:00    30.11\n",
       "2020-01-13 23:00:00+00:00      NaN\n",
       "2020-01-14 00:00:00+00:00    30.09\n",
       "2020-01-14 01:00:00+00:00    30.10\n",
       "2020-01-14 02:00:00+00:00    30.10\n",
       "2020-01-14 03:00:00+00:00    30.10\n",
       "2020-01-14 04:00:00+00:00    30.09\n",
       "2020-01-14 05:00:00+00:00    30.10\n",
       "2020-01-14 06:00:00+00:00    30.12\n",
       "2020-01-14 07:00:00+00:00    30.13\n",
       "2020-01-14 08:00:00+00:00    30.14\n",
       "2020-01-14 09:00:00+00:00    30.15\n",
       "2020-01-14 10:00:00+00:00    30.16\n",
       "2020-01-14 11:00:00+00:00    30.12\n",
       "2020-01-14 12:00:00+00:00    30.07\n",
       "2020-01-14 13:00:00+00:00    30.05\n",
       "2020-01-14 14:00:00+00:00    30.05\n",
       "2020-01-14 15:00:00+00:00    30.05\n",
       "2020-01-14 16:00:00+00:00    30.04\n",
       "2020-01-14 17:00:00+00:00    30.05\n",
       "2020-01-14 18:00:00+00:00    30.05\n",
       "2020-01-14 19:00:00+00:00    30.05\n",
       "2020-01-14 20:00:00+00:00    30.07\n",
       "2020-01-14 21:00:00+00:00    30.09\n",
       "2020-01-14 22:00:00+00:00    30.08\n",
       "2020-01-14 23:00:00+00:00      NaN\n",
       "Name: hourlysealevelpressure, Length: 44022, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.hourlyrelativehumidity.astype('float64')\n",
    "weather_df.hourlysealevelpressure.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dailycoolingdegreedays        float64\n",
       "dailyheatingdegreedays        float64\n",
       "hourlydewpointtemperature     float64\n",
       "hourlydrybulbtemperature      float64\n",
       "hourlyprecipitation           float64\n",
       "hourlyrelativehumidity        float64\n",
       "hourlysealevelpressure        float64\n",
       "hourlyskyconditions          category\n",
       "hourlystationpressure         float64\n",
       "hourlyvisibility              float64\n",
       "hourlywindspeed               float64\n",
       "hourlycoolingdegrees          float64\n",
       "hourlyheatingdegrees          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cut dataframes based on date to align sources\n",
    "cut_electricity = electricity_df[:weather_df.index.max()]\n",
    "cut_weather = weather_df[cut_electricity.index.min():]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with outliers and NaN values\n",
    "\n",
    "The plot distributions bof the features below is used to determine what columns should be filled by using the median\n",
    "and which should be filled according to ffill. The features whose ```medians``` and ```means``` are close together suggest that the ```median``` is a good choice for NaNs.Conversely features whose median and means are further apart suggest the presence of outliers and in this case I use ```ffill``` because we are dealing with time series and values in previous time steps are useful in predicting values for later time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_dict = {'median': ['dailyheatingdegreedays', 'hourlyaltimetersetting', 'hourlydrybulbtemperature', 'hourlyprecipitation', 'hourlysealevelpressure', 'hourlystationpressure', 'hourlywetbulbtempf', 'dailycoolingdegreedays', 'hourlyvisibility', 'hourlywindspeed', 'hourlycoolingdegrees', 'hourlyheatingdegrees'], 'ffill': ['demand', 'hourlydewpointtempf', 'hourlyrelativehumidity']}\n",
    "\n",
    "# fill electricity data NaNs\n",
    "for col in cut_electricity.columns:\n",
    "    if col in fill_dict['median']:\n",
    "        cut_electricity[col].fillna(cut_electricity[col].median(), inplace=True)\n",
    "    else:\n",
    "        cut_electricity[col].fillna(cut_electricity[col].ffill(), inplace=True)\n",
    "\n",
    "# fill weather data NaNs\n",
    "for col in cut_weather.columns:\n",
    "    if col == 'hourlyskyconditions':\n",
    "        cut_weather[col].fillna(cut_weather[col].value_counts().index[0], inplace=True) \n",
    "    elif col in fill_dict['median']:\n",
    "        cut_weather[col].fillna(cut_weather[col].median(), inplace=True)\n",
    "    else:\n",
    "        cut_weather[col].fillna(cut_weather[col].ffill(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 outliers found out of 39566 data points, 0.015164535206995905% of the data. 6870.0 is the max\n"
     ]
    }
   ],
   "source": [
    "def find_outliers(df, column, lim_scalar=4, print_result=False):\n",
    "    \"\"\"\n",
    "    Returns outliers above the max limit for a column in a dataframe\n",
    "    Adjust outlier cutoff to q75 + 4*iqr to include more data\n",
    "    ---\n",
    "    input: DataFrame, column(series), lim_scalar(float), print_result(boolean)\n",
    "    output: DataFrame\n",
    "    \"\"\"\n",
    "    q25, q50, q75 = df[column].quantile(q=[0.25, 0.5, 0.75])\n",
    "    iqr = q75 - q25\n",
    "    # max limits to be considered an outlier\n",
    "    max_ = q75 + lim_scalar * iqr\n",
    "    # identify the points\n",
    "    outlier_mask = [True if x > max_ else False for x in df[column]]\n",
    "    if print_result:\n",
    "        print('{} outliers found out of {} data points, {}% of the data. {} is the max'.format(\n",
    "        sum(outlier_mask), len(df[column]),\n",
    "        100 * (sum(outlier_mask) / len(df[column])),max_))\n",
    "    return outlier_mask\n",
    "\n",
    "demand_outliers = find_outliers(cut_electricity, 'demand', lim_scalar=4, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_electricity = cut_electricity[np.logical_not(find_outliers(cut_electricity, 'demand',lim_scalar=4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** min ***\n",
      "2015-07-01 08:00:00+00:00\n",
      "2015-07-01 08:00:00+00:00\n",
      "True\n",
      "*** max ***\n",
      "2020-01-14 23:00:00+00:00\n",
      "2020-01-14 23:00:00+00:00\n",
      "True\n",
      "*** instances quantity is equal? ***\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('*** min ***')\n",
    "print(min(cut_electricity.index))\n",
    "print(min(cut_weather.index))\n",
    "print(cut_weather.index.min() == cut_electricity.index.min())\n",
    "print('*** max ***')\n",
    "print(max(cut_electricity.index))\n",
    "print(max(cut_weather.index))\n",
    "print(cut_weather.index.max() == cut_electricity.index.max())\n",
    "print('*** instances quantity is equal? ***')\n",
    "print(cut_weather.shape[0] == cut_electricity.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "***\n",
      "Before 39670\n",
      "***\n",
      "After 39422\n"
     ]
    }
   ],
   "source": [
    "electricity_set = set(cut_electricity.index)\n",
    "weather_set = set(cut_weather.index)\n",
    "\n",
    "difference = weather_set.difference(electricity_set)\n",
    "print(len(weather_set.difference(electricity_set)))\n",
    "print('***')\n",
    "print('Before ' + str(cut_weather.shape[0]))\n",
    "print('***')\n",
    "cut_weather = cut_weather.drop(list(difference), axis=0)\n",
    "difference = electricity_set.difference(weather_set)\n",
    "cut_electricity = cut_electricity.drop(list(difference), axis=0)\n",
    "print('After ' + str(cut_weather.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(cut_weather.shape[0] == cut_electricity.shape[0])\n",
    "electricity_set = set(cut_electricity.index)\n",
    "weather_set = set(cut_weather.index)\n",
    "print(len(electricity_set.difference(weather_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally merge the data to get a complete dataframe for LA, ready for training\n",
    "merged_df = cut_weather.merge(cut_electricity, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.get_dummies(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dailycoolingdegreedays</th>\n",
       "      <th>dailyheatingdegreedays</th>\n",
       "      <th>hourlydewpointtemperature</th>\n",
       "      <th>hourlydrybulbtemperature</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlyrelativehumidity</th>\n",
       "      <th>hourlysealevelpressure</th>\n",
       "      <th>hourlystationpressure</th>\n",
       "      <th>hourlyvisibility</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "      <th>hourlycoolingdegrees</th>\n",
       "      <th>hourlyheatingdegrees</th>\n",
       "      <th>demand</th>\n",
       "      <th>hourlyskyconditions_BKN</th>\n",
       "      <th>hourlyskyconditions_CLR</th>\n",
       "      <th>hourlyskyconditions_FEW</th>\n",
       "      <th>hourlyskyconditions_OVC</th>\n",
       "      <th>hourlyskyconditions_SCT</th>\n",
       "      <th>hourlyskyconditions_VV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01 08:00:00+00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>29.92</td>\n",
       "      <td>29.73</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3298.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-01 09:00:00+00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.92</td>\n",
       "      <td>29.73</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3045.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-01 10:00:00+00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>29.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-01 11:00:00+00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>29.87</td>\n",
       "      <td>29.68</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-01 12:00:00+00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29.86</td>\n",
       "      <td>29.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dailycoolingdegreedays  dailyheatingdegreedays  \\\n",
       "datetime                                                                    \n",
       "2015-07-01 08:00:00+00:00                    11.0                     0.0   \n",
       "2015-07-01 09:00:00+00:00                    11.0                     0.0   \n",
       "2015-07-01 10:00:00+00:00                    11.0                     0.0   \n",
       "2015-07-01 11:00:00+00:00                    11.0                     0.0   \n",
       "2015-07-01 12:00:00+00:00                    11.0                     0.0   \n",
       "\n",
       "                           hourlydewpointtemperature  \\\n",
       "datetime                                               \n",
       "2015-07-01 08:00:00+00:00                       63.0   \n",
       "2015-07-01 09:00:00+00:00                       64.0   \n",
       "2015-07-01 10:00:00+00:00                       63.0   \n",
       "2015-07-01 11:00:00+00:00                       61.0   \n",
       "2015-07-01 12:00:00+00:00                       61.0   \n",
       "\n",
       "                           hourlydrybulbtemperature  hourlyprecipitation  \\\n",
       "datetime                                                                   \n",
       "2015-07-01 08:00:00+00:00                      74.0                  0.0   \n",
       "2015-07-01 09:00:00+00:00                      77.0                  0.0   \n",
       "2015-07-01 10:00:00+00:00                      82.0                  0.0   \n",
       "2015-07-01 11:00:00+00:00                      84.0                  0.0   \n",
       "2015-07-01 12:00:00+00:00                      81.0                  0.0   \n",
       "\n",
       "                           hourlyrelativehumidity  hourlysealevelpressure  \\\n",
       "datetime                                                                    \n",
       "2015-07-01 08:00:00+00:00                    69.0                   29.92   \n",
       "2015-07-01 09:00:00+00:00                    64.0                   29.92   \n",
       "2015-07-01 10:00:00+00:00                    53.0                   29.91   \n",
       "2015-07-01 11:00:00+00:00                    46.0                   29.87   \n",
       "2015-07-01 12:00:00+00:00                    51.0                   29.86   \n",
       "\n",
       "                           hourlystationpressure  hourlyvisibility  \\\n",
       "datetime                                                             \n",
       "2015-07-01 08:00:00+00:00                  29.73              10.0   \n",
       "2015-07-01 09:00:00+00:00                  29.73              10.0   \n",
       "2015-07-01 10:00:00+00:00                  29.71              10.0   \n",
       "2015-07-01 11:00:00+00:00                  29.68              10.0   \n",
       "2015-07-01 12:00:00+00:00                  29.67              10.0   \n",
       "\n",
       "                           hourlywindspeed  hourlycoolingdegrees  \\\n",
       "datetime                                                           \n",
       "2015-07-01 08:00:00+00:00              0.0                   9.0   \n",
       "2015-07-01 09:00:00+00:00              0.0                  12.0   \n",
       "2015-07-01 10:00:00+00:00              0.0                  17.0   \n",
       "2015-07-01 11:00:00+00:00              3.0                  19.0   \n",
       "2015-07-01 12:00:00+00:00              3.0                  16.0   \n",
       "\n",
       "                           hourlyheatingdegrees  demand  \\\n",
       "datetime                                                  \n",
       "2015-07-01 08:00:00+00:00                   0.0  3298.0   \n",
       "2015-07-01 09:00:00+00:00                   0.0  3045.0   \n",
       "2015-07-01 10:00:00+00:00                   0.0  2892.0   \n",
       "2015-07-01 11:00:00+00:00                   0.0  2787.0   \n",
       "2015-07-01 12:00:00+00:00                   0.0  2790.0   \n",
       "\n",
       "                           hourlyskyconditions_BKN  hourlyskyconditions_CLR  \\\n",
       "datetime                                                                      \n",
       "2015-07-01 08:00:00+00:00                        0                        1   \n",
       "2015-07-01 09:00:00+00:00                        0                        0   \n",
       "2015-07-01 10:00:00+00:00                        0                        1   \n",
       "2015-07-01 11:00:00+00:00                        0                        1   \n",
       "2015-07-01 12:00:00+00:00                        0                        1   \n",
       "\n",
       "                           hourlyskyconditions_FEW  hourlyskyconditions_OVC  \\\n",
       "datetime                                                                      \n",
       "2015-07-01 08:00:00+00:00                        0                        0   \n",
       "2015-07-01 09:00:00+00:00                        1                        0   \n",
       "2015-07-01 10:00:00+00:00                        0                        0   \n",
       "2015-07-01 11:00:00+00:00                        0                        0   \n",
       "2015-07-01 12:00:00+00:00                        0                        0   \n",
       "\n",
       "                           hourlyskyconditions_SCT  hourlyskyconditions_VV  \n",
       "datetime                                                                    \n",
       "2015-07-01 08:00:00+00:00                        0                       0  \n",
       "2015-07-01 09:00:00+00:00                        0                       0  \n",
       "2015-07-01 10:00:00+00:00                        0                       0  \n",
       "2015-07-01 11:00:00+00:00                        0                       0  \n",
       "2015-07-01 12:00:00+00:00                        0                       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['hourlyskyconditions_VV'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9eb07dbf237b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hourlyskyconditions_VV'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hourlyskyconditions_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4964\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4965\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['hourlyskyconditions_VV'] not found in axis\""
     ]
    }
   ],
   "source": [
    "merged_df.drop('hourlyskyconditions_VV', axis=1, inplace=True)\n",
    "merged_df.drop('hourlyskyconditions_', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'AF272D1C08D40958',\n",
       "  'HostId': '/56XiK5BApE5BpXrN6ql5gLoE6vvHBOkOMTX94veBduY1avf9bXlVB1DQaoJiuBHDE3ILa8IuWk=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '/56XiK5BApE5BpXrN6ql5gLoE6vvHBOkOMTX94veBduY1avf9bXlVB1DQaoJiuBHDE3ILa8IuWk=',\n",
       "   'x-amz-request-id': 'AF272D1C08D40958',\n",
       "   'date': 'Thu, 16 Jan 2020 17:11:03 GMT',\n",
       "   'etag': '\"755bfdd0887b5206cfbce9d382e9e8d0\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"755bfdd0887b5206cfbce9d382e9e8d0\"'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save as csv file to continue in another notebook\n",
    "csv_buffer = io.StringIO()\n",
    "s3_resource = boto3.resource('s3')\n",
    "key = 'dataframes/%s_dataset.csv' % CITY\n",
    "\n",
    "merged_df.to_csv(csv_buffer, compression=None)\n",
    "s3_resource.Object(bucket, key).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
