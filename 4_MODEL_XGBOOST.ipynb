{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Energy Demand \n",
    "\n",
    "## Modeling\n",
    "My approach treats the problem as a standard supervised regression task. Given a set of features – the time and weather information – we want to build a model that can predict the continuous target, energy consumption. The model is trained on the past historical energy consumption using the features and the target and then can be used to make predictions for future dates where only the features are known.\n",
    "\n",
    "* Train/Test Split\n",
    "* Scale all features using a min-max scaler\n",
    "* Fit data with model\n",
    "* Evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install xgboost in notebook instance.\n",
    "#### Command to install xgboost\n",
    "!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AWS and Sagemaker SDKs and get files access\n",
    "import boto3\n",
    "import io\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket ='sagemaker-data-energy-demand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# XGBoost \n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "\n",
    "CITY = 'LosAngeles'\n",
    "train_key = 'dataframes/%s_reframed_train.csv' % CITY\n",
    "validation_key = 'dataframes/%s_reframed_validation.csv' % CITY\n",
    "\n",
    "train_location = 's3://{}/{}'.format(bucket, train_key)\n",
    "validation_location = 's3://{}/{}'.format(bucket, validation_key)\n",
    "\n",
    "df_train = pd.read_csv(train_location, index_col='datetime')\n",
    "df_validation = pd.read_csv(validation_location, index_col='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train = pd.DataFrame(df_train['demand(t)'])\n",
    "plot_validation = pd.DataFrame(df_validation['demand(t)'])\n",
    "plot_train.index = df_train.index\n",
    "plot_validation.index = df_validation.index\n",
    "\n",
    "to_plot = plot_validation \\\n",
    "    .rename(columns={'demand(t)': 'VALIDATION SET'}) \\\n",
    "    .join(plot_train.rename(columns={'demand(t)': 'TRAINING SET'}), how='outer') \\\n",
    "\n",
    "\n",
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(y=to_plot['TRAINING SET'], x=to_plot.index,\n",
    "                    mode='lines',\n",
    "                    name='TRAINING SET'))\n",
    "fig.add_trace(go.Scattergl(y=to_plot['VALIDATION SET'], x=to_plot.index,\n",
    "                    mode='lines',\n",
    "                    name='VALIDATION SET',\n",
    "                    marker_color='rgb(0, 204, 150)'))\n",
    "fig.update_layout(title='Los Angeles - Train/Validation Split',\n",
    "                   xaxis_title='Date',\n",
    "                   yaxis_title='Electricity Demand [MWh]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sppliter(df, label):\n",
    "    cols = list(df.columns)\n",
    "    cols.remove(label)\n",
    "    X = df[cols]\n",
    "    y = df[label]\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = data_sppliter(df_train, label='demand(t)')\n",
    "X_validation, y_validation = data_sppliter(df_validation, label='demand(t)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Training Parameter Reference: \n",
    "# https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "\n",
    "regressor = xgb.XGBRegressor(max_depth=5, n_estimators=960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_validation, y_validation)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['demand(t)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = regressor.evals_result()\n",
    "training_rounds = range(len(eval_result['validation_0']['rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=training_rounds,y=eval_result['validation_0']['rmse'],label='Training Error')\n",
    "plt.scatter(x=training_rounds,y=eval_result['validation_1']['rmse'],label='Validation Error')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training Vs Validation Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance plot\n",
    "Feature importance is a great way to get a general idea about which features the model is relying on most to make the prediction. This is a metric that simply sums up how many times each feature is split on.\n",
    "We can see that the hour was most commonly used to split trees alongside day of year and day of week, while weather features has low importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 16))\n",
    "xgb.plot_importance(regressor, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation['demand_prediction'] = regressor.predict(X_validation)\n",
    "df_all = pd.concat([df_validation, df_train], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(y=df_all['demand(t)'], x=df_all.index,\n",
    "                    mode='markers',\n",
    "                    name='TRAINING SET'))\n",
    "fig.add_trace(go.Scattergl(y=df_all['demand_prediction'], x=df_all.index,\n",
    "                    mode='lines',\n",
    "                    name='PREDICT SET'))\n",
    "fig.update_layout(title='Los Angeles - Forecast On Test',\n",
    "                   xaxis_title='Date',\n",
    "                   yaxis_title='Electricity Demand [MWh]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zooming-in at first month of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "first_month = df_all.head(720)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(y=first_month['demand(t)'], x=first_month.index,\n",
    "                    mode='lines',\n",
    "                    name='TRAINING SET'))\n",
    "fig.add_trace(go.Scattergl(y=first_month['demand_prediction'], x=first_month.index,\n",
    "                    mode='lines',\n",
    "                    name='TEST SET'))\n",
    "fig.update_layout(title='Forecast vs Actuals - First Month',\n",
    "                   xaxis_title='Date',\n",
    "                   yaxis_title='Electricity Demand [MWh]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "first_month = df_all.head(168)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(y=first_month['demand(t)'], x=first_month.index,\n",
    "                    mode='markers',\n",
    "                    name='TEST SET'))\n",
    "fig.add_trace(go.Scattergl(y=first_month['demand_prediction'], x=first_month.index,\n",
    "                    mode='lines',\n",
    "                    name='PREDICT SET'))\n",
    "fig.update_layout(title='Forecast vs Actuals - First Month',\n",
    "                   xaxis_title='Date',\n",
    "                   yaxis_title='Electricity Demand [MWh]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Metrics On Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y_true=df_validation['demand(t)'],\n",
    "                   y_pred=df_validation['demand_prediction'])\n",
    "\n",
    "mae = mean_absolute_error(y_true=df_validation['demand(t)'],\n",
    "                   y_pred=df_validation['demand_prediction'])\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_true=df_validation['demand(t)'],\n",
    "                   y_pred=df_validation['demand_prediction'])\n",
    "\n",
    "print(rmse)\n",
    "print(mae)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Worst and Best Predicted Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation['error'] = df_validation['demand(t)'] - df_validation['demand_prediction']\n",
    "df_validation['abs_error'] = df_validation['error'].apply(np.abs)\n",
    "error_by_day = df_validation.groupby(['year(t)','month(t)','dayofmonth(t)']) \\\n",
    "    .mean()[['demand(t)','demand_prediction','error','abs_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst predicted days\n",
    "error_by_day.sort_values('error', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best predicted days\n",
    "error_by_day.sort_values('abs_error', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Prophet Model\n",
    "Prophet model expects the dataset to be named a specific way. We will rename our dataframe columns before feeding it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data for prophet model using ds and y\n",
    "prophet_train = df_train.copy()\n",
    "prophet_train = prophet_train.reset_index() \\\n",
    "                .rename(columns={'datetime':'ds',\n",
    "                                 'demand(t)':'y'}).head()\n",
    "\n",
    "[str(i)[:-6] for i in prophet_train['ds']]\n",
    "prophet_train.ds = prophet_train.ds.dt.tz_convert(tz=None)\n",
    "prophet_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and train model\n",
    "model = Prophet()\n",
    "model.fit(prophet_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet__to_test = df_test.reset_index().rename(columns={'datetime':'ds'})\n",
    "prophet__to_test.ds = prophet__to_test.ds.dt.tz_convert(tz=None)\n",
    "prophet_test = model.predict(df=prophet__to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast with the actuals\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "ax.scatter(df_test.index, df_test['demand_prediction'], color='r')\n",
    "fig = model.plot(prophet_test, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
